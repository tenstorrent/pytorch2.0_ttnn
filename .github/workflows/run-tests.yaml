name: "Run Tests"
on:
  workflow_call:
    inputs:
      commit_report:
        description: 'Commit generated report files: None, Docs, All'
        required: false
        type: string
        default: 'None'
      docker_tag:
        description: 'Docker container tag to use'
        required: false
        type: string
        default: 'ghcr.io/tenstorrent/pytorch2.0_ttnn/ubuntu-22.04-amd64:latest'
      mock_run:
        description: "Array of test groups to run. If empty, all tests will be run."
        required: false
        type: string
        default: ""
    outputs:
      tests_passed:
        description: "Whether tests passed (0 means pass, 1 means fail)"
        value: ${{ jobs.tests-passed.outputs.didpass }}
      pull_request_number:
        description: "Number of created pull request, if it exists"
        value: ${{ jobs.push-autogen-op-tests.outputs.pull-request-number || jobs.collect-metrics.outputs.pull-request-number }}
  workflow_dispatch:
    inputs:
      commit_report:
        description: 'Commit generated report files: None, Docs, All'
        required: false
        type: string
        default: 'None'
      docker_tag:
        description: 'Docker container tag to use'
        required: false
        type: string
        default: 'ghcr.io/tenstorrent/pytorch2.0_ttnn/ubuntu-22.04-amd64:latest'

permissions:
  actions: read
  contents: write
  pages: write
  id-token: write
  pull-requests: write

jobs:
  tools-tests:
    env:
      pytest_verbosity: 2    
      pytest_report_title: "⭐️ Tools Tests"
    runs-on: ["in-service"]
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GH_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
    steps:      
      - uses: actions/checkout@v4
      - uses: ./.github/actions/common_repo_setup
      - name: Run Tools Tests 
        run: |
          python3 -m pytest --github-report tests/tools/ -s

  lowering-tests:
    runs-on: ["in-service"]
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GH_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
    env:
      pytest_verbosity: 2    
      pytest_report_title: "⭐️ Aten → TTNN Lowering Tests"
    strategy:
      matrix: # Need to find a way to replace this with a generator
        group: [1, 2]
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/common_repo_setup
      - uses: ./.github/actions/common_lowering_tests

  count-test-files:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.count-files.outputs.matrix }}
      num_files: ${{ steps.count-files.outputs.num_files }}
    env:
      MOCK_RUN: ${{ github.event.inputs.mock_run }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Count Test Files
        id: count-files
        uses: ./.github/actions/count_test_files
        with:
          test_directory: 'tests/models/'

  model-tests:
    needs: [count-test-files, lowering-tests]
    runs-on: ["in-service", "nfs"]
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GH_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
        -v /mnt/tt-metal-pytorch-cache/.cache:/root/.cache
    env:      
      pytest_verbosity: 0
      pytest_report_title: "⭐️ Model Tests - Group ${{ matrix.group }}"    
      TORCH_HOME: /root/.cache/torch
      HF_HOME: /root/.cache/huggingface
    strategy:
      matrix: 
        group: ${{ fromJson(needs.count-test-files.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true
          fetch-depth: 0    
      - uses: ./.github/actions/common_repo_setup
      - name: docker-cleanup
        run: |
          docker system prune -a -f
          df -h  # Debug space
      - uses: ./.github/actions/common_model_tests
        with:
          splits: ${{ needs.count-test-files.outputs.num_files }}
          matrix_group: ${{ matrix.group }}
          commit_report: ${{ github.event.inputs.commit_report }}
      - name: Upload Metrics Artifact
        if: success()  # Only run if tests passed
        uses: actions/upload-artifact@v4
        with:
          name: model-tests-metrics-group-${{ matrix.group }}
          path: metrics/

  get-pr-branch:
    if: ${{ inputs.commit_report != 'None' }}
    runs-on: ubuntu-latest
    outputs:
      branch-name: ${{ steps.create-branch.outputs.branch-name }}
    steps:
      - name: Create PR Branch Name
        id: create-branch
        run: |
          echo "branch-name=update-docs-$(date +%s)" >> $GITHUB_OUTPUT

  multi-device-tests:
    needs: lowering-tests
    runs-on: ["in-service", "nfs", "n300"]
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GH_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
        -v /mnt/tt-metal-pytorch-cache/.cache:/root/.cache
    env:
      pytest_verbosity: 0
      pytest_report_title: "⭐️ Multi-Device Tests"
      TORCH_HOME: /root/.cache/torch
      HF_HOME: /root/.cache/huggingface
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true
          fetch-depth: 0
      - uses: ./.github/actions/common_repo_setup
      - uses: ./.github/actions/common_multi_device_tests
        with:
          commit_report: ${{ github.event.inputs.commit_report }}
      - name: Upload Metrics Artifact
        if: success()  # Only run if tests passed
        uses: actions/upload-artifact@v4
        with:
          name: multi-device-tests-metrics
          path: metrics/

  push-autogen-op-tests:
    needs: [model-tests, get-pr-branch]
    if: ${{ inputs.commit_report != 'None' }}
    runs-on: ["in-service"]
    outputs:
      pull-request-number: ${{ steps.push-op-tests.outputs.pull-request-number }}
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GH_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
    env:
      BRANCH_NAME: ${{ github.head_ref || github.ref_name }}
      PYTHONPATH: ${{ github.workspace }}
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/common_repo_setup

      - name: Download All Metrics Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: model-tests-metrics-group-*
          merge-multiple: true
          path: metrics/

      - name: Generate Op Tests
        id: generate-op-tests
        run: |
          rm -rf tests/autogen_op/ # Remove old tests
          python3 tools/generate_input_variation_test_from_models.py
          python3 tools/generate_input_variation_test_from_models.py --merge=True
          if [ "${{ inputs.commit_report }}" == "All" ]; then
            echo "commit-glob=." >> $GITHUB_OUTPUT
          elif [ "${{ inputs.commit_report }}" == "Tests" ]; then
            echo "commit-glob=tests/*" >> $GITHUB_OUTPUT
          else
            echo "commit-glob=nothing" >> $GITHUB_OUTPUT
            echo "No files will be committed"
          fi

      - name: Push Autogen Op Tests
        uses: peter-evans/create-pull-request@v7
        id: push-op-tests
        if: ${{ steps.generate-op-tests.outputs.commit-glob != 'nothing' }}
        with:
          branch: ${{ needs.get-pr-branch.outputs.branch-name }}
          committer: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>
          author: ${{ github.actor }} <${{ github.actor_id }}+${{ github.actor }}@users.noreply.github.com>
          base: main
          commit-message: "[auto][on-merge-queue] Update input variations tests"
          title: "Update PT2.0 Documentation"
          body: "This PR updates Documentation by rerunning autogenerated tests"          
          delete-branch: true
          token: ${{ secrets.GH_TOKEN }}
          add-paths: ${{ steps.generate-op-tests.outputs.commit-glob }}

  model-autogen-op-tests:
    needs: [push-autogen-op-tests, count-test-files]
    if: ${{ inputs.commit_report != 'None' }}
    runs-on: ["in-service"]
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GH_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
    strategy:
      matrix: 
        group: ${{ fromJson(needs.count-test-files.outputs.matrix) }}
    env:
      pytest_verbosity: 0
      pytest_report_title: "⭐️ Model Input Variations Tests - Group ${{ matrix.group }}"
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/common_repo_setup

      - name: Run Model Input Variations Tests
        run: |
          set +e
          rm -rf tests/autogen_op/ALL
          python3 -m pytest --github-report tests/autogen_op --splits ${{ needs.count-test-files.outputs.num_files }} --group ${{ matrix.group }} -s
          exit_code=$?  # Capture the exit code, but ignore any errors for now.
          ls -l
          cd metrics-autogen-op
          ls -l
          cd ..
          exit 0;

      - name: Upload Input Variations Metrics Artifact
        if: success()  # Only run if tests passed
        uses: actions/upload-artifact@v4
        with:
          name: model-autogen-op-tests-metrics-group-${{ matrix.group }}
          path: metrics-autogen-op/

  collect-model-artifacts-from-matrix-jobs:
    needs: model-tests
    runs-on: ubuntu-latest
    env:
      pytest_verbosity: 0
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/common_repo_setup
      - name: Download All Metrics Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: model-tests-metrics-group-*
          merge-multiple: true
          path: metrics/

      - name: Upload Metrics Artifact
        if: success()  # Only run if tests passed
        uses: actions/upload-artifact@v4
        with:
          name: model-tests-metrics
          path: metrics/

  collect-op-artifacts-from-matrix-jobs:
    needs: model-autogen-op-tests
    runs-on: ubuntu-latest
    env:
      pytest_verbosity: 0
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/common_repo_setup
      - name: Download All Input Variations Metrics Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: model-autogen-op-tests-metrics-group-*
          merge-multiple: true
          path: metrics-autogen-op/

      - name: Upload Input Variations Metrics Artifact
        uses: actions/upload-artifact@v4
        with:
          name: model-autogen-op-tests-metrics
          path: metrics-autogen-op/

  collect-metrics:
    needs: [model-autogen-op-tests, push-autogen-op-tests, get-pr-branch]
    if: ${{ inputs.commit_report != 'None'}}
    runs-on: ["in-service"]
    outputs:
      pull-request-number: ${{ steps.push-metrics-report.outputs.pull-request-number }}
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GH_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
    env:
      BRANCH_NAME: ${{ github.head_ref || github.ref_name }}
      PYTHONPATH: ${{ github.workspace }}
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/common_repo_setup
      - name: Download All Metrics Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: model-tests-metrics-group-*
          merge-multiple: true
          path: metrics/

      - name: Download All Input Variations Metrics Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: model-autogen-op-tests-metrics-group-*
          merge-multiple: true
          path: metrics-autogen-op/
      # - name: Download Metrics Artifacts
      #   env:
      #     GH_TOKEN: ${{ secrets.GH_TOKEN }}
      #     GH_REPO: ${{ github.repository }}
      #   run: |
      #     mkdir -p metrics
      #     for i in $(seq 1 40); do
      #       echo "Downloading metrics for Group $i"
      #       gh run download ${{ github.run_id }} --name "model-tests-metrics-group-$i" --dir metrics/
      #       cd metrics
      #       ls -l
      #       cd ..
      #     done

      - name: Collect Metrics Report
        id: collect-metrics
        run: |
          python3 tools/collect_metrics.py

          if [ "${{ inputs.commit_report }}" = "All" ]; then
            echo "commit-glob=." >> $GITHUB_OUTPUT
          elif [ "${{ inputs.commit_report }}" = "Docs" ]; then
            echo "commit-glob=README.md,docs/*" >> $GITHUB_OUTPUT
          else
            echo "commit-glob=nothing" >> $GITHUB_OUTPUT
            echo "No files will be committed"
            exit 0
          fi

      - name: Push Metrics Report
        uses: peter-evans/create-pull-request@v7
        id: push-metrics-report
        if: ${{ steps.collect-metrics.outputs.commit-glob != 'nothing' }}
        with:
          branch: ${{ needs.get-pr-branch.outputs.branch-name }}
          committer: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>
          author: ${{ github.actor }} <${{ github.actor_id }}+${{ github.actor }}@users.noreply.github.com>
          base: main
          commit-message: "[auto][on-merge-queue] Update metrics report in README.md"
          title: "Update PT2.0 Documentation"
          body: "This PR updates Documentation by rerunning autogenerated tests"          
          delete-branch: true
          token: ${{ secrets.GH_TOKEN }}
          add-paths: ${{ steps.collect-metrics.outputs.commit-glob }}

      - name: Send To Data Team
        run: |
          python3 tools/send_to_data_team.py \
              --github_workflow_id ${{ github.run_id }} \
              --sftp_host ${{ secrets.SFTP_OPTEST_HOST }} \
              --sftp_user ${{ secrets.SFTP_OPTEST_USER }} \
              --sftp_private_key ${{ secrets.SFTP_OPTEST_PRIVATE_KEY }}

  tests-passed:
    if: ${{ always() }}
    outputs:
      didpass: ${{ steps.check.outputs.didpass }}
    runs-on: ubuntu-latest    
    needs: [model-tests, multi-device-tests, tools-tests, lowering-tests, collect-metrics]
    steps:
      - id: check
        run: |
          model_result="${{ needs.model-tests.result}}"
          multi_device_result="${{ needs.multi-device-tests.result}}"
          tools_result="${{ needs.tools-tests.result}}"
          lowering_result="${{ needs.lowering-tests.result}}"
          if [[ ($tools_result == "success" || $tools_result == "skipped") && 
                ($multi_device_result == "success" || $multi_device_result == "skipped") && 
                ($lowering_result == "success" || $lowering_result == "skipped") && 
                ($model_result == "success" || $model_result == "skipped") ]] ; then
            echo "didpass=0" >> $GITHUB_OUTPUT
            exit 0
          else
            echo "didpass=1" >> $GITHUB_OUTPUT
            exit 1
          fi
