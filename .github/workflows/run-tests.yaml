name: "Run Tests"
on:
  workflow_call:
    inputs:
      commit_report:
        description: 'Commit generated report files: None, Docs, All'
        required: false
        type: string
        default: 'None'
      docker_tag:
        description: 'Docker container tag to use'
        required: false
        type: string
        # TODO: Using pinned tt-metal Docker image for project freeze (Nov 18, 2025)
        # To update: docker manifest inspect --verbose ghcr.io/tenstorrent/tt-metal/tt-metalium/ubuntu-22.04-ci-test-amd64:latest
        default: 'ghcr.io/tenstorrent/tt-metal/tt-metalium/ubuntu-22.04-ci-test-amd64@sha256:104b062b1942b398902884d6340a9695fbfcd4ffe6fb5a59f3d6363c499e7fce'
      mock_run:
        description: "Array of test groups to run. If empty, all tests will be run."
        required: false
        type: string
        default: ""
      enable_telemetry:
        description: 'Whether to enable telemetry (will fail if enabled but permissions are missing)'
        required: false
        type: string
        default: 'false'
      install_full_dependencies:
        description: 'Install full tt-metal dependencies (unchecked = use --sfpi flag only)'
        required: false
        type: boolean
        default: true
    outputs:
      tests_passed:
        description: "Whether tests passed (0 means pass, 1 means fail)"
        value: ${{ jobs.tests-passed.outputs.didpass }}
      pull_request_number:
        description: "Number of created pull request, if it exists"
        value: ${{ jobs.push-autogen-op-tests.outputs.pull-request-number || jobs.collect-metrics.outputs.pull-request-number }}
  workflow_dispatch:
    inputs:
      commit_report:
        description: 'Commit generated report files: None, Docs, All'
        required: false
        type: string
        default: 'None'
      docker_tag:
        description: 'Docker container tag to use'
        required: false
        type: string
        # TODO: Using pinned tt-metal Docker image for project freeze (Nov 18, 2025)
        # To update: docker manifest inspect --verbose ghcr.io/tenstorrent/tt-metal/tt-metalium/ubuntu-22.04-ci-test-amd64:latest
        default: 'ghcr.io/tenstorrent/tt-metal/tt-metalium/ubuntu-22.04-ci-test-amd64@sha256:104b062b1942b398902884d6340a9695fbfcd4ffe6fb5a59f3d6363c499e7fce'
      enable_telemetry:
        description: 'Whether to enable telemetry (will fail if enabled but permissions are missing)'
        required: false
        type: string
        default: 'false'
      install_full_dependencies:
        description: 'Install full tt-metal dependencies (unchecked = use --sfpi flag only)'
        required: false
        type: boolean
        default: true

permissions:
  actions: read
  contents: write
  pages: write
  id-token: write
  pull-requests: write

defaults:
  run:
    shell: bash --noprofile --norc -u -x {0}

jobs:
  log-parameters:
    runs-on: ubuntu-latest
    steps:
      - name: Log Workflow Parameters
        run: |
          echo "=========================================="
          echo "ðŸ”§ Workflow Parameters"
          echo "=========================================="
          echo "commit_report: ${{ inputs.commit_report }}"
          echo "docker_tag: ${{ inputs.docker_tag }}"
          echo "enable_telemetry: ${{ inputs.enable_telemetry }}"
          echo "install_full_dependencies: ${{ inputs.install_full_dependencies }}"
          if [ "${{ inputs.install_full_dependencies }}" == "true" ]; then
            echo "  â†’ Will run: ./install_dependencies.sh (full install)"
          else
            echo "  â†’ Will run: ./install_dependencies.sh --sfpi (sfpi only)"
          fi
          echo "=========================================="

  tools-tests:
    needs: log-parameters
    env:
      pytest_verbosity: 2    
      pytest_report_title: "â­ï¸ Tools Tests"
      PIP_CACHE_DIR: /root/pip_cache/.pip_cache
      HF_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
      TT_METAL_HOME: ${{ github.workspace }}/torch_ttnn/cpp_extension/third-party/tt-metal
    runs-on: ["in-service"]
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
    steps:
      # Install git-lfs before checkout (required for lfs: true)
      - name: Install git-lfs
        run: |
          apt-get update
          apt-get install -y git-lfs
          git lfs install
      # Explicit checkout with submodules: false to prevent GitHub Actions from scanning
      # submodule .github/actions directories during "Prepare all required actions" phase.
      - uses: actions/checkout@v4
        with:
          lfs: true
          submodules: false
          fetch-depth: 1
      - uses: ./.github/actions/common_repo_setup
        with:
          clean: 'true'
          enable-telemetry: ${{ inputs.enable_telemetry || 'false' }}
          install-full-dependencies: ${{ inputs.install_full_dependencies || 'true' }}
      - name: Run Tools Tests 
        run: |
          python3 -m pytest --github-report tests/tools/ -s

  lowering-tests:
    needs: ["tools-tests"]
    runs-on: ["in-service"]
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
    env:
      pytest_verbosity: 2    
      pytest_report_title: "â­ï¸ Aten â†’ TTNN Lowering Tests"
      PIP_CACHE_DIR: /root/pip_cache/.pip_cache
      TT_METAL_HOME: ${{ github.workspace }}/torch_ttnn/cpp_extension/third-party/tt-metal
    strategy:
      matrix: # Need to find a way to replace this with a generator
        group: [1, 2]
    steps:
      # Install git-lfs before checkout (required for lfs: true)
      - name: Install git-lfs
        run: |
          apt-get update
          apt-get install -y git-lfs
          git lfs install
      # Explicit checkout with submodules: false to prevent GitHub Actions from scanning
      # submodule .github/actions directories during "Prepare all required actions" phase.
      - uses: actions/checkout@v4
        with:
          lfs: true
          submodules: false
          fetch-depth: 1
      - uses: ./.github/actions/common_repo_setup
        with:
          enable-telemetry: ${{ inputs.enable_telemetry || 'false' }}
          install-full-dependencies: ${{ inputs.install_full_dependencies || 'true' }}
      - uses: ./.github/actions/common_lowering_tests

  count-test-files:
    needs: log-parameters
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.count-files.outputs.matrix }}
      num_files: ${{ steps.count-files.outputs.num_files }}
    env:
      MOCK_RUN: ${{ inputs.mock_run }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Count Test Files
        id: count-files
        uses: ./.github/actions/count_test_files
        with:
          test_directory: 'tests/models/'

  model-tests:
    needs: [count-test-files, lowering-tests]
    runs-on: ["in-service", "nfs"]
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
        -v /mnt/tt-metal-pytorch-cache/.cache:/root/.cache
    env:      
      pytest_verbosity: 0
      pytest_report_title: "â­ï¸ Model Tests - Group ${{ matrix.group }}"    
      TORCH_HOME: /root/.cache/torch
      HF_HOME: /root/.cache/huggingface
      HF_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
      PIP_CACHE_DIR: /root/pip_cache/.pip_cache
      TT_METAL_HOME: ${{ github.workspace }}/torch_ttnn/cpp_extension/third-party/tt-metal
    strategy:
      matrix: 
        group: ${{ fromJson(needs.count-test-files.outputs.matrix) }}
    steps:
      # Install git-lfs before checkout (required for lfs: true)
      - name: Install git-lfs
        run: |
          apt-get update
          apt-get install -y git-lfs
          git lfs install
      # Explicit checkout with submodules: false to prevent GitHub Actions from scanning
      # submodule .github/actions directories during "Prepare all required actions" phase.
      - uses: actions/checkout@v4
        with:
          lfs: true
          submodules: false
          fetch-depth: 1
      - uses: ./.github/actions/common_repo_setup
        with:
          enable-telemetry: ${{ inputs.enable_telemetry || 'false' }}
          install-full-dependencies: ${{ inputs.install_full_dependencies || 'true' }}
      - uses: ./.github/actions/common_cleanup
        with:
          docker-cleanup: 'true'
      - uses: ./.github/actions/common_model_tests
        with:
          splits: ${{ needs.count-test-files.outputs.num_files }}
          matrix_group: ${{ matrix.group }}
          commit_report: ${{ inputs.commit_report }}
      - name: Upload Metrics Artifact
        if: success()  # Only run if tests passed
        uses: actions/upload-artifact@v4
        with:
          name: model-tests-metrics-group-${{ matrix.group }}
          path: metrics/

  get-pr-branch:
    if: ${{ inputs.commit_report != 'None' }}
    runs-on: ubuntu-latest
    outputs:
      branch-name: ${{ steps.create-branch.outputs.branch-name }}
    steps:
      - name: Create PR Branch Name
        id: create-branch
        run: |
          echo "branch-name=update-docs-$(date +%s)" >> $GITHUB_OUTPUT

  multi-device-tests:
    needs: lowering-tests
    runs-on: >-
      ${{
        ('tt-ubuntu-2204-n300-stable')
        || fromJSON('["n300", "in-service", "nfs"]')
      }}
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      env:
        PYTHONPATH: /work
        GITHUB_ACTIONS: true
      volumes:
        - ${{ github.workspace }}:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /mnt/tt-metal-pytorch-cache/.cache:/root/.cache
      options: >-
        --rm 
        --device /dev/tenstorrent
    env:
      pytest_verbosity: 0
      pytest_report_title: "â­ï¸ Multi-Device Tests"
      TORCH_HOME: /root/.cache/torch
      HF_HOME: /root/.cache/huggingface
      PIP_CACHE_DIR: /root/pip_cache/.pip_cache
      TT_METAL_HOME: ${{ github.workspace }}/torch_ttnn/cpp_extension/third-party/tt-metal
    steps:
      # Install git-lfs before checkout (required for lfs: true)
      - name: Install git-lfs
        run: |
          apt-get update
          apt-get install -y git-lfs
          git lfs install
      # Explicit checkout with submodules: false to prevent GitHub Actions from scanning
      # submodule .github/actions directories during "Prepare all required actions" phase.
      - uses: actions/checkout@v4
        with:
          lfs: true
          submodules: false
          fetch-depth: 1
      - uses: ./.github/actions/common_repo_setup
        with:
          enable-telemetry: ${{ inputs.enable_telemetry || 'false' }}
          install-full-dependencies: ${{ inputs.install_full_dependencies || 'true' }}
      - uses: ./.github/actions/common_multi_device_tests
        with:
          commit_report: ${{ inputs.commit_report }}
      - name: Upload Metrics Artifact
        if: success()  # Only run if tests passed
        uses: actions/upload-artifact@v4
        with:
          name: multi-device-tests-metrics
          path: metrics/

  push-autogen-op-tests:
    needs: [model-tests, get-pr-branch]
    if: ${{ inputs.commit_report != 'None' }}
    runs-on: ["in-service"]
    outputs:
      pull-request-number: ${{ steps.push-op-tests.outputs.pull-request-number }}
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
    env:
      BRANCH_NAME: ${{ github.head_ref || github.ref_name }}
      PYTHONPATH: ${{ github.workspace }}
      PIP_CACHE_DIR: /root/pip_cache/.pip_cache
    steps:
      # Install git-lfs before checkout (required for lfs: true)
      - name: Install git-lfs
        run: |
          apt-get update
          apt-get install -y git-lfs
          git lfs install
      # Explicit checkout with submodules: false to prevent GitHub Actions from scanning
      # submodule .github/actions directories during "Prepare all required actions" phase.
      - uses: actions/checkout@v4
        with:
          lfs: true
          submodules: false
          fetch-depth: 1
      - uses: ./.github/actions/common_repo_setup
        with:
          enable-telemetry: ${{ inputs.enable_telemetry || 'false' }}
          install-full-dependencies: ${{ inputs.install_full_dependencies || 'true' }}

      - name: Download All Metrics Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: model-tests-metrics-group-*
          merge-multiple: true
          path: metrics/

      - name: Generate Op Tests
        id: generate-op-tests
        run: |
          rm -rf tests/autogen_op/ # Remove old tests
          python3 tools/generate_input_variation_test_from_models.py
          python3 tools/generate_input_variation_test_from_models.py --merge=True
          if [ "${{ inputs.commit_report }}" == "All" ]; then
            echo "commit-glob=." >> $GITHUB_OUTPUT
          elif [ "${{ inputs.commit_report }}" == "Tests" ]; then
            echo "commit-glob=tests/*" >> $GITHUB_OUTPUT
          else
            echo "commit-glob=nothing" >> $GITHUB_OUTPUT
            echo "No files will be committed"
          fi

      - name: Push Autogen Op Tests
        uses: peter-evans/create-pull-request@v7
        id: push-op-tests
        if: ${{ steps.generate-op-tests.outputs.commit-glob != 'nothing' }}
        with:
          branch: ${{ needs.get-pr-branch.outputs.branch-name }}
          committer: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>
          author: ${{ github.actor }} <${{ github.actor_id }}+${{ github.actor }}@users.noreply.github.com>
          base: main
          commit-message: "[auto][on-merge-queue] Update input variations tests"
          title: "Update PT2.0 Documentation"
          body: "This PR updates Documentation by rerunning autogenerated tests"          
          delete-branch: true
          token: ${{ secrets.GITHUB_TOKEN }}
          add-paths: ${{ steps.generate-op-tests.outputs.commit-glob }}

  model-autogen-op-tests:
    needs: [push-autogen-op-tests, count-test-files]
    if: ${{ inputs.commit_report != 'None' }}
    runs-on: ["in-service"]
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
    strategy:
      matrix: 
        group: ${{ fromJson(needs.count-test-files.outputs.matrix) }}
    env:
      pytest_verbosity: 0
      pytest_report_title: "â­ï¸ Model Input Variations Tests - Group ${{ matrix.group }}"
      PIP_CACHE_DIR: /root/pip_cache/.pip_cache
      TT_METAL_HOME: ${{ github.workspace }}/torch_ttnn/cpp_extension/third-party/tt-metal
    steps:
      # Install git-lfs before checkout (required for lfs: true)
      - name: Install git-lfs
        run: |
          apt-get update
          apt-get install -y git-lfs
          git lfs install
      # Explicit checkout with submodules: false to prevent GitHub Actions from scanning
      # submodule .github/actions directories during "Prepare all required actions" phase.
      - uses: actions/checkout@v4
        with:
          lfs: true
          submodules: false
          fetch-depth: 1
      - uses: ./.github/actions/common_repo_setup
        with:
          enable-telemetry: ${{ inputs.enable_telemetry || 'false' }}
          install-full-dependencies: ${{ inputs.install_full_dependencies || 'true' }}

      - name: Run Model Input Variations Tests
        run: |
          set +e
          rm -rf tests/autogen_op/ALL
          python3 -m pytest --github-report tests/autogen_op --splits ${{ needs.count-test-files.outputs.num_files }} --group ${{ matrix.group }} -s
          exit_code=$?  # Capture the exit code, but ignore any errors for now.
          ls -l
          cd metrics-autogen-op
          ls -l
          cd ..
          exit 0;

      - name: Upload Input Variations Metrics Artifact
        if: success()  # Only run if tests passed
        uses: actions/upload-artifact@v4
        with:
          name: model-autogen-op-tests-metrics-group-${{ matrix.group }}
          path: metrics-autogen-op/

  collect-model-artifacts-from-matrix-jobs:
    needs: model-tests
    runs-on: ubuntu-latest
    env:
      pytest_verbosity: 0
    steps:
      # Install git-lfs before checkout (required for lfs: true)
      - name: Install git-lfs
        run: |
          apt-get update
          apt-get install -y git-lfs
          git lfs install
      # Explicit checkout with submodules: false to prevent GitHub Actions from scanning
      # submodule .github/actions directories during "Prepare all required actions" phase.
      - uses: actions/checkout@v4
        with:
          lfs: true
          submodules: false
          fetch-depth: 1
      - uses: ./.github/actions/common_repo_setup
        with:
          enable-telemetry: ${{ inputs.enable_telemetry || 'false' }}
          install-full-dependencies: ${{ inputs.install_full_dependencies || 'true' }}
      - name: Download All Metrics Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: model-tests-metrics-group-*
          merge-multiple: true
          path: metrics/

      - name: Upload Metrics Artifact
        if: success()  # Only run if tests passed
        uses: actions/upload-artifact@v4
        with:
          name: model-tests-metrics
          path: metrics/

  collect-op-artifacts-from-matrix-jobs:
    needs: model-autogen-op-tests
    runs-on: ubuntu-latest
    env:
      pytest_verbosity: 0
    steps:
      # Install git-lfs before checkout (required for lfs: true)
      - name: Install git-lfs
        run: |
          apt-get update
          apt-get install -y git-lfs
          git lfs install
      # Explicit checkout with submodules: false to prevent GitHub Actions from scanning
      # submodule .github/actions directories during "Prepare all required actions" phase.
      - uses: actions/checkout@v4
        with:
          lfs: true
          submodules: false
          fetch-depth: 1
      - uses: ./.github/actions/common_repo_setup
        with:
          enable-telemetry: ${{ inputs.enable_telemetry || 'false' }}
          install-full-dependencies: ${{ inputs.install_full_dependencies || 'true' }}
      - name: Download All Input Variations Metrics Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: model-autogen-op-tests-metrics-group-*
          merge-multiple: true
          path: metrics-autogen-op/

      - name: Upload Input Variations Metrics Artifact
        uses: actions/upload-artifact@v4
        with:
          name: model-autogen-op-tests-metrics
          path: metrics-autogen-op/

  collect-metrics:
    needs: [model-autogen-op-tests, push-autogen-op-tests, get-pr-branch]
    if: ${{ inputs.commit_report != 'None'}}
    runs-on: ["in-service"]
    outputs:
      pull-request-number: ${{ steps.push-metrics-report.outputs.pull-request-number }}
    container: 
      image: ${{ inputs.docker_tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: >-
        --rm -v /dev/hugepages-1G:/dev/hugepages-1G --device /dev/tenstorrent
        -v ${{ github.workspace }}:${{ github.workspace }} -w ${{ github.workspace }}
    env:
      BRANCH_NAME: ${{ github.head_ref || github.ref_name }}
      PYTHONPATH: ${{ github.workspace }}
      PIP_CACHE_DIR: /root/pip_cache/.pip_cache
    steps:
      # Install git-lfs before checkout (required for lfs: true)
      - name: Install git-lfs
        run: |
          apt-get update
          apt-get install -y git-lfs
          git lfs install
      # Explicit checkout with submodules: false to prevent GitHub Actions from scanning
      # submodule .github/actions directories during "Prepare all required actions" phase.
      - uses: actions/checkout@v4
        with:
          lfs: true
          submodules: false
          fetch-depth: 1
      - uses: ./.github/actions/common_repo_setup
        with:
          enable-telemetry: ${{ inputs.enable_telemetry || 'false' }}
          install-full-dependencies: ${{ inputs.install_full_dependencies || 'true' }}
      - name: Download All Metrics Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: model-tests-metrics-group-*
          merge-multiple: true
          path: metrics/

      - name: Download All Input Variations Metrics Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: model-autogen-op-tests-metrics-group-*
          merge-multiple: true
          path: metrics-autogen-op/
      # - name: Download Metrics Artifacts
      #   env:
      #     GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      #     GH_REPO: ${{ github.repository }}
      #   run: |
      #     mkdir -p metrics
      #     for i in $(seq 1 40); do
      #       echo "Downloading metrics for Group $i"
      #       gh run download ${{ github.run_id }} --name "model-tests-metrics-group-$i" --dir metrics/
      #       cd metrics
      #       ls -l
      #       cd ..
      #     done

      - name: Collect Metrics Report
        id: collect-metrics
        run: |
          python3 tools/collect_metrics.py

          if [ "${{ inputs.commit_report }}" = "All" ]; then
            echo "commit-glob=." >> $GITHUB_OUTPUT
          elif [ "${{ inputs.commit_report }}" = "Docs" ]; then
            echo "commit-glob=README.md,docs/*" >> $GITHUB_OUTPUT
          else
            echo "commit-glob=nothing" >> $GITHUB_OUTPUT
            echo "No files will be committed"
            exit 0
          fi

      - name: Push Metrics Report
        uses: peter-evans/create-pull-request@v7
        id: push-metrics-report
        if: ${{ steps.collect-metrics.outputs.commit-glob != 'nothing' }}
        with:
          branch: ${{ needs.get-pr-branch.outputs.branch-name }}
          committer: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>
          author: ${{ github.actor }} <${{ github.actor_id }}+${{ github.actor }}@users.noreply.github.com>
          base: main
          commit-message: "[auto][on-merge-queue] Update metrics report in README.md"
          title: "Update PT2.0 Documentation"
          body: "This PR updates Documentation by rerunning autogenerated tests"          
          delete-branch: true
          token: ${{ secrets.GITHUB_TOKEN }}
          add-paths: ${{ steps.collect-metrics.outputs.commit-glob }}

      - name: Send To Data Team
        run: |
          # Add to known hosts and create id_rsa file
          mkdir -p ~/.ssh && touch ~/.ssh/known_hosts
          ssh-keyscan ${{ secrets.SFTP_OPTEST_HOST }} >> ~/.ssh/known_hosts
          
          rm -rf ~/.ssh/id_rsa
          echo "${{ secrets.SFTP_OPTEST_PRIVATE_KEY }}" >> ~/.ssh/id_rsa
          chmod 400 ~/.ssh/id_rsa
          
          python3 tools/send_to_data_team.py \
              --github_workflow_id ${{ github.run_id }} \
              --sftp_host ${{ secrets.SFTP_OPTEST_HOST }} \
              --sftp_user ${{ secrets.SFTP_OPTEST_USER }} \
              --sftp_private_key_path ~/.ssh/id_rsa

  tests-passed:
    if: ${{ always() }}
    outputs:
      didpass: ${{ steps.check.outputs.didpass }}
    runs-on: ubuntu-latest    
    needs: [model-tests, multi-device-tests, tools-tests, lowering-tests, collect-metrics]
    steps:
      - id: check
        run: |
          model_result="${{ needs.model-tests.result}}"
          multi_device_result="${{ needs.multi-device-tests.result}}"
          tools_result="${{ needs.tools-tests.result}}"
          lowering_result="${{ needs.lowering-tests.result}}"
          if [[ ($tools_result == "success" || $tools_result == "skipped") && 
                ($multi_device_result == "success" || $multi_device_result == "skipped") && 
                ($lowering_result == "success" || $lowering_result == "skipped") && 
                ($model_result == "success" || $model_result == "skipped") ]] ; then
            echo "didpass=0" >> $GITHUB_OUTPUT
            exit 0
          else
            echo "didpass=1" >> $GITHUB_OUTPUT
            exit 1
          fi
