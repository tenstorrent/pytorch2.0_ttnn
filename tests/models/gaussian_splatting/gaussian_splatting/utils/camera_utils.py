# SPDX-FileCopyrightText: https://github.com/hbb1/torch-splatting/blob/6c9792/gaussian_splatting/utils/camera_utils.py © 2025 Binbin Huang
# SPDX-FileCopyrightText: Modifications © 2025 Tenstorrent AI ULC
# SPDX-License-Identifier: MIT AND Apache-2.0

import torch
import torch.nn as nn
import math
import numpy as np


def parse_camera(params):
    H = params[:, 0]
    W = params[:, 1]
    intrinsics = params[:, 2:18].reshape((-1, 4, 4))
    c2w = params[:, 18:34].reshape((-1, 4, 4))
    return H, W, intrinsics, c2w


def to_viewpoint_camera(camera):
    """
    Parse a camera of intrinsic and c2w into a Camera Object
    """
    device = camera.device
    Hs, Ws, intrinsics, c2ws = parse_camera(camera.unsqueeze(0))
    camera = Camera(width=int(Ws[0]), height=int(Hs[0]), intrinsic=intrinsics[0], c2w=c2ws[0])
    return camera


class Camera(nn.Module):
    def __init__(
        self, width, height, intrinsic, c2w, znear=0.1, zfar=100.0, trans=np.array([0.0, 0.0, 0.0]), scale=1.0
    ):
        super(Camera, self).__init__()
        device = c2w.device
        self.znear = znear
        self.zfar = zfar
        self.focal_x, self.focal_y = intrinsic[0, 0], intrinsic[1, 1]
        self.FoVx = focal2fov(self.focal_x, width)
        self.FoVy = focal2fov(self.focal_y, height)
        self.image_width = int(width)
        self.image_height = int(height)
        # torch.inverse does not work with half precision, so convert to single then reconvert to half
        assert c2w.is_floating_point()
        if torch.finfo(c2w.dtype).bits < 32:
            self.world_view_transform = torch.linalg.inv(c2w.to(torch.float)).permute(1, 0).to(c2w.dtype)
            self.camera_center = self.world_view_transform.to(torch.float).inverse()[3, :3].to(c2w.dtype)
        else:
            self.world_view_transform = torch.linalg.inv(c2w).permute(1, 0)
            self.camera_center = self.world_view_transform.inverse()[3, :3]
        self.intrinsic = intrinsic
        self.c2w = c2w
        self.projection_matrix = getProjectionMatrix(
            znear=self.znear, zfar=self.zfar, fovX=self.FoVx, fovY=self.FoVy
        ).transpose(0, 1)
        self.full_proj_transform = self.world_view_transform @ self.projection_matrix


def fov2focal(fov, pixels):
    return pixels / (2 * math.tan(fov / 2))


def focal2fov(focal, pixels):
    return 2 * math.atan(pixels / (2 * focal))


def getWorld2View2(R, t, translate=np.array([0.0, 0.0, 0.0]), scale=1.0):
    Rt = np.zeros((4, 4))
    Rt[:3, :3] = R.transpose()
    Rt[:3, 3] = t
    Rt[3, 3] = 1.0

    C2W = np.linalg.inv(Rt)
    cam_center = C2W[:3, 3]
    cam_center = (cam_center + translate) * scale
    C2W[:3, 3] = cam_center
    Rt = np.linalg.inv(C2W)
    return np.float32(Rt)


def getProjectionMatrix(znear, zfar, fovX, fovY):
    tanHalfFovY = math.tan((fovY / 2))
    tanHalfFovX = math.tan((fovX / 2))

    top = tanHalfFovY * znear
    bottom = -top
    right = tanHalfFovX * znear
    left = -right

    P = torch.zeros(4, 4)

    z_sign = 1.0

    P[0, 0] = 2.0 * znear / (right - left)
    P[1, 1] = 2.0 * znear / (top - bottom)
    P[0, 2] = (right + left) / (right - left)
    P[1, 2] = (top + bottom) / (top - bottom)
    P[3, 2] = z_sign
    P[2, 2] = z_sign * zfar / (zfar - znear)
    P[2, 3] = -(zfar * znear) / (zfar - znear)
    return P
